# -*- coding: utf-8 -*-
"""Untitled115.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-JL6RSmYbH2PSQUi3nlvQ8EySHy_LfRp
"""

import os
import pickle
import faiss
import numpy as np
import requests
import streamlit as st
from sentence_transformers import SentenceTransformer

# ---------- 1. Load data & models (cached) ----------
@st.cache_resource(show_spinner=False)
def load_resources():
    index = faiss.read_index("cse_index.faiss")
    with open("cse_chunks.pkl", "rb") as f:
        chunks = pickle.load(f)
    embedder = SentenceTransformer("BAAI/bge-small-en-v1.5")
    return index, chunks, embedder

index, chunks, embedder = load_resources()

# ---------- 2. Helper functions ----------
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]          # stored in secrets.toml
GROQ_URL      = "https://api.groq.com/openai/v1/chat/completions"
MODEL_NAME    = "llama3-8b-8192"

def retrieve_context(query, k=2):
    query_vec = embedder.encode([query])
    D, I = index.search(np.array(query_vec), k)
    return "\n".join(chunks[i] for i in I[0])

def call_groq(system_prompt, user_prompt):
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type":  "application/json"
    }
    body = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": user_prompt}
        ],
        "temperature": 0.4,
        "max_tokens": 800
    }
    resp = requests.post(GROQ_URL, headers=headers, json=body, timeout=30)
    resp.raise_for_status()
    return resp.json()["choices"][0]["message"]["content"]

def generate_answer(user_msg):
    context = retrieve_context(user_msg)
    system_prompt = (
        "You are FYATâ€¯AIâ€¯1.0, a helpful BRAC University CSE assistant. "
        "Answer strictly based on the context below, but fix grammar / formatting:\n\n"
        f"{context}\n\n"
        "If the context is insufficient, politely direct the user to "
        "https://cse.sds.bracu.ac.bd/ and https://www.bracu.ac.bd/."
    )
    return call_groq(system_prompt, user_msg)

# ---------- 3. Streamlit UI ----------
st.set_page_config(page_title="FYATâ€¯AI â€“ BRACUâ€¯CSE Assistant", page_icon="ðŸª„")

st.title("ðŸª„ FYATâ€¯AI: BRACUâ€¯CSE Knowledge Assistant")
st.caption("Powered by BAAI embeddings + Llamaâ€¯3â€‘8B (GROQ)")

with st.expander("Disclaimer", expanded=False):
    st.markdown(
        "This tool provides information for educational purposes only and is **not** a "
        "substitute for FYAT Mentors or official university resources."
    )

# Chat history lives in session_state
if "history" not in st.session_state:
    st.session_state.history = []

# Display past messages
for role, msg in st.session_state.history:
    st.chat_message(role).markdown(msg)

# User input box
user_msg = st.chat_input("Ask me anything about BRACUâ€¯CSEâ€¦")

if user_msg:
    st.chat_message("user").markdown(user_msg)
    with st.chat_message("assistant"):
        with st.spinner("Thinkingâ€¦"):
            answer = generate_answer(user_msg)
            st.markdown(answer)
    # Update history
    st.session_state.history.append(("user", user_msg))
    st.session_state.history.append(("assistant", answer))